{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27cc5509-75ad-4148-93b8-088b97ad1b17",
   "metadata": {
    "id": "27cc5509-75ad-4148-93b8-088b97ad1b17"
   },
   "source": [
    "<p align=center>\n",
    "<img src=\"assets/cphbanner.png\" width=1280>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014c2e32-3dfb-418a-b462-43537d11fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "path_to_project = os.path.abspath(os.path.join(os.getcwd(), '../'))    \n",
    "sys.path.insert(1, os.path.join(path_to_project))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c79aea8-f578-4310-9e04-46fed86f21f1",
   "metadata": {
    "id": "2c79aea8-f578-4310-9e04-46fed86f21f1"
   },
   "source": [
    "# **Project 1: Survival Analysis and Prediction [30 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f62d3c-682e-44df-bda2-c04125cdb7a8",
   "metadata": {
    "id": "a9f62d3c-682e-44df-bda2-c04125cdb7a8"
   },
   "source": [
    "Many clinical trials and observational studies involve following patients for a long time. The primary event of\n",
    "interest in those studies may include death, relapse, or the onset of a new disease. The follow-up time for a trial\n",
    "or a study may range from few weeks to many years. To analyze this data, we typically conduct time-to-event\n",
    "analysis and build predictive models that learn time-to-event distributions. The goal of this project is to test\n",
    "your ability to conduct basic survival analyses as well as develop ML models for survival prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345becba-b634-48c3-9130-b7071af5e878",
   "metadata": {
    "id": "345becba-b634-48c3-9130-b7071af5e878"
   },
   "source": [
    "**Please submit your report and code by <u> Tuesday 2/4 11:59 PST </u>.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ac5b5a-a269-46be-bf9a-a300b535809f",
   "metadata": {
    "id": "03ac5b5a-a269-46be-bf9a-a300b535809f"
   },
   "source": [
    "## Task 1.1: Nonparametric Survival Analysis in Heart Failure [7 pts]\n",
    "\n",
    "Nonparametric models of survival data do not make parametric assumptions on the distribution of timeto-event outcomes. They are widely used in clinical studies to derive descriptive statistics of survival in a population. In this task, we will apply standard nonparametric estimators to analyze survival of heart failure patients in a recent, widely-recognized study [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fdb3da-c55d-46a3-a277-82260a5b8298",
   "metadata": {
    "id": "c0fdb3da-c55d-46a3-a277-82260a5b8298"
   },
   "source": [
    "####  Setup and Dataset\n",
    "\n",
    "The dataset we will use in this task was extracted from the electronic health records (EHRs) of 299 heart failure patients from the Faisalabad Institute of Cardiology and at the Allied Hospital in Faisalabad (Punjab, Pakistan), during April–December 2015. The cohort included 105 women and 194 men, and their ages range between 40 and 95 years old. All 299 patients had left ventricular systolic dysfunction and had previous heart failures (HF) that put them in classes III or IV of New York Heart Association (NYHA) classification of the stages of heart failure. The dataset contains 13 features, which report clinical, body, and lifestyle information. The patients were followed up for 130 days on average (maximum follow-up period was 285 days). The event of interest was death during the follow-up period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e3b06b-9959-4feb-8700-e22e2cee7918",
   "metadata": {
    "id": "f1e3b06b-9959-4feb-8700-e22e2cee7918"
   },
   "source": [
    "The dataset is publicly accessible and was shared with the class through UCSF Box. You can load the dataset in the directory \"./data\" and inspect all the features/outcomes using pandas as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2e885c-2106-49c8-9bd9-979919e5efa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:21:26.386831Z",
     "start_time": "2025-01-17T23:21:26.384336Z"
    },
    "id": "bc2e885c-2106-49c8-9bd9-979919e5efa6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from src.directory import csv_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228683f099a2712",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:21:26.626657Z",
     "start_time": "2025-01-17T23:21:26.621803Z"
    }
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "dataset = pd.read_csv(csv_paths['faisalabad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e169f044fb712899",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:21:26.676897Z",
     "start_time": "2025-01-17T23:21:26.666305Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d4409-6dc3-412d-b931-f4544b0353ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:21:26.742009Z",
     "start_time": "2025-01-17T23:21:26.707998Z"
    },
    "id": "c75d4409-6dc3-412d-b931-f4544b0353ce",
    "outputId": "9ab13dd2-b6e3-4968-e9f5-c60615d3bf31"
   },
   "outputs": [],
   "source": [
    "# descriptive statistics\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70539b63bd443d95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:21:26.747412Z",
     "start_time": "2025-01-17T23:21:26.743151Z"
    }
   },
   "outputs": [],
   "source": [
    "# check for NaN\n",
    "print(f'NA Count by Variable : {dataset.isna().sum(axis=0)[dataset.isna().sum(axis=0) > 0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21442ab-caf2-4dae-acf9-ca225a272d9d",
   "metadata": {
    "id": "d21442ab-caf2-4dae-acf9-ca225a272d9d"
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820ca3a2ac060a6a",
   "metadata": {},
   "source": [
    "### Task 1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f23307cc71027",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T00:12:10.954120Z",
     "start_time": "2025-01-18T00:12:10.951393Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from lifelines import KaplanMeierFitter\n",
    "from src.estimators import kaplan_meier\n",
    "from src.directory import csv_paths\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d937e7f111fcc07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T00:12:11.166836Z",
     "start_time": "2025-01-18T00:12:11.160698Z"
    }
   },
   "outputs": [],
   "source": [
    "time_col = 'time'\n",
    "event_col = 'DEATH_EVENT'\n",
    "dataset = pd.read_csv(csv_paths['faisalabad'])\n",
    "\n",
    "# set alpha for confidence intervals\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2536f4f0dd1ba42a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T00:12:11.486365Z",
     "start_time": "2025-01-18T00:12:11.480157Z"
    }
   },
   "outputs": [],
   "source": [
    "# get KM estimate from scratch\n",
    "km_df = kaplan_meier(dataset, time_col, event_col, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec2d6b14fc67c5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T00:12:11.864192Z",
     "start_time": "2025-01-18T00:12:11.847637Z"
    }
   },
   "outputs": [],
   "source": [
    "# get KM estimate from lifelines\n",
    "kmf = KaplanMeierFitter(alpha=alpha)\n",
    "kmf.fit(dataset['time'], event_observed=dataset['DEATH_EVENT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e885fa1cbe077b17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T00:12:12.521455Z",
     "start_time": "2025-01-18T00:12:12.420449Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot KM estimates from scratch and with lifelines\n",
    "fig, axs = plt.subplots()\n",
    "\n",
    "# plot from scratch KM\n",
    "sns.lineplot(data=km_df, x='time', y='survival_prob', \n",
    "             drawstyle='steps-pre', ax=axs, label='From scratch', legend=True)\n",
    "plt.fill_between(km_df['time'], km_df['ci_lower'], km_df['ci_upper'], alpha=0.3)\n",
    "\n",
    "# plot lifelines KM\n",
    "kmf.plot_survival_function(label='Lifelines')\n",
    "\n",
    "plt.ylim(.45, 1.05)\n",
    "plt.title(fr'Kaplan-Meier Estimates, CI $\\alpha$ ={alpha}')\n",
    "plt.show()\n",
    "\n",
    "# check survival function equality\n",
    "assert all(np.isclose(km_df['survival_prob'].values.ravel(),\n",
    "                      kmf.survival_function_.reindex(range(km_df['time'].max() +1)).ffill().values.ravel())), 'Survival functions don\\'t match!'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e80f62a34462af5",
   "metadata": {},
   "source": [
    "### Task 1.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90026a63b692998",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:21:27.319184Z",
     "start_time": "2025-01-17T23:21:27.317080Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d626c9d13141757a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:21:27.330499Z",
     "start_time": "2025-01-17T23:21:27.320125Z"
    }
   },
   "outputs": [],
   "source": [
    "eps = 1e-8\n",
    "\n",
    "def exp_model(x, a, b, c):\n",
    "    return a * np.exp(-b * x) + c\n",
    "\n",
    "popt, pcov = curve_fit(f=exp_model, xdata=km_df.index, ydata=km_df['survival_prob'])\n",
    "S_t = exp_model(km_df.index, *popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ffd8224f9e2523",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:21:27.404546Z",
     "start_time": "2025-01-17T23:21:27.331485Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot KM estimates from scratch and with lifelines\n",
    "fig2, axs2 = plt.subplots()\n",
    "\n",
    "# plot from scratch KM\n",
    "sns.lineplot(data=km_df, x='time', y='survival_prob', \n",
    "             drawstyle='steps-pre', ax=axs2, label='Empirical curve', legend=True)\n",
    "plt.fill_between(km_df['time'], km_df['ci_lower'], km_df['ci_upper'], alpha=0.3)\n",
    "\n",
    "axs2.plot(S_t, label='Exponential Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Limitation: no guaranteed y==0 at x==0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af77fc875718dd",
   "metadata": {},
   "source": [
    "### Task 1.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc15a246b6797b59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:21:29.264585Z",
     "start_time": "2025-01-17T23:21:27.405185Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.data_dict import feature_config\n",
    "from src.estimators import nearest_neighbor_km\n",
    "from src.metrics import evaluate_c_index\n",
    "\n",
    "dataset_name = 'faisalabad'\n",
    "patient_features = feature_config[dataset_name]\n",
    "time_col = 'time'\n",
    "event_col = 'DEATH_EVENT'\n",
    "max_time = dataset[time_col].max()\n",
    "\n",
    "patient_km_fits = nearest_neighbor_km(dataset, patient_features, time_col, event_col, n_neighbors=20)\n",
    "\n",
    "c_index = evaluate_c_index(dataset, patient_km_fits, time_col, event_col)\n",
    "print(f\"C-index: {c_index}\")\n",
    "\n",
    "#Example of getting survival probabilites for a specific patient\n",
    "fig, axs = plt.subplots()\n",
    "for patient_index in range(5):\n",
    "    time_points = np.arange(max_time)\n",
    "    patient_survival_prob = patient_km_fits[patient_index].survival_function_at_times(time_points)\n",
    "    patient_survival_prob.index.name = time_col\n",
    "    \n",
    "    sns.lineplot(data=patient_survival_prob.reset_index(), x='time', y='KM_estimate', \n",
    "                 drawstyle='steps-pre', ax=axs, label=f'Patient {patient_index}', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f0da4e0b0e337",
   "metadata": {},
   "source": [
    "## Task 1.2: Survival Prediction in HF patients using the Cox Model [7 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105bbc1730cc22ca",
   "metadata": {},
   "source": [
    "### Task 1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab011fa6bdd0dc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:21:30.895790Z",
     "start_time": "2025-01-17T23:21:29.265822Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.data_dict import feature_config\n",
    "from src.lightning import CoxRiskLightning, get_trainer, get_checkpoint_callback, get_log_dir_path\n",
    "from src.dataset import SurvivalDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e69d3cd8b73653",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:21:31.877658Z",
     "start_time": "2025-01-17T23:21:30.896893Z"
    }
   },
   "outputs": [],
   "source": [
    "time_col = 'time'\n",
    "event_col = 'DEATH_EVENT'\n",
    "dataset_name = 'faisalabad'\n",
    "\n",
    "# set up datamodule\n",
    "datamodule = SurvivalDataModule(\n",
    "    dataset_name=dataset_name,\n",
    "    input_features=feature_config[dataset_name],\n",
    "    time_col=time_col,\n",
    "    event_col=event_col\n",
    ")\n",
    "\n",
    "# set up model \n",
    "model = CoxRiskLightning(\n",
    "    dataset_name=dataset_name,\n",
    "    clinical_features=feature_config[dataset_name],\n",
    "    time_col=time_col,\n",
    "    event_col=event_col\n",
    ")\n",
    "\n",
    "# set log dir\n",
    "model_name = 'cox'\n",
    "log_dir_path = get_log_dir_path(model_name)\n",
    "\n",
    "# get checkpoint callback\n",
    "checkpoint_callback = get_checkpoint_callback(model_name, log_dir_path)\n",
    "\n",
    "# get trainer\n",
    "trainer = get_trainer(model_name, checkpoint_callback)\n",
    "\n",
    "print(\"Training model\")\n",
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda30a89a2b03722",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_coefficients = model.model.risk.weight.squeeze().detach().numpy()\n",
    "\n",
    "feature_of_interest = 'age'\n",
    "idx = model.feature_names.index(feature_of_interest)\n",
    "effect_of_increment = np.exp(model_coefficients[idx])\n",
    "print(f'\\nHazard Ratio of 1-year increment of {feature_of_interest} on risk:', effect_of_increment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f1c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficient_df = pd.DataFrame(model_coefficients, index=feature_config[dataset_name], columns=['Model coefficients'])\n",
    "latex_tab = coefficient_df.to_latex(index=True, \n",
    "                            float_format=\"%.3f\",\n",
    "                            label=f'tab:cox_coefficients',\n",
    "                            caption=f'Cox model coefficients',\n",
    "                            sparsify=True)\n",
    "latex_tab = latex_tab.replace('_', ' ')\n",
    "print(latex_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebf42d758c600a7",
   "metadata": {},
   "source": [
    "### Task 1.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5745795cf5936cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run train set through model\n",
    "predict_trainer = get_trainer(model_name, checkpoint_callback)\n",
    "_ = predict_trainer.predict(model, datamodule)\n",
    "metrics = model.metric_dict\n",
    "print('C-index on train set:', metrics['predict']['predict_cindex'])\n",
    "print('AUC-ROC on train set:', metrics['predict']['predict_auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68490f1247a3e468",
   "metadata": {},
   "source": [
    "### Task 1.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d5b77aa9232ec5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:51:54.975447Z",
     "start_time": "2025-01-17T23:51:54.889331Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.dataset import merge_batches\n",
    "from src.data_dict import feature_config\n",
    "from src.lightning import CoxRiskLightning, get_trainer, get_checkpoint_callback, get_log_dir_path\n",
    "from src.dataset import SurvivalDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff1506d7af866bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:51:56.259359Z",
     "start_time": "2025-01-17T23:51:55.222648Z"
    }
   },
   "outputs": [],
   "source": [
    "time_col = 'time'\n",
    "event_col = 'DEATH_EVENT'\n",
    "dataset_name = 'faisalabad'\n",
    "\n",
    "# set up datamodule\n",
    "datamodule = SurvivalDataModule(\n",
    "    dataset_name=dataset_name,\n",
    "    input_features=feature_config[dataset_name],\n",
    "    time_col=time_col,\n",
    "    event_col=event_col\n",
    ")\n",
    "\n",
    "# set up model \n",
    "model = CoxRiskLightning(\n",
    "    dataset_name=dataset_name,\n",
    "    clinical_features=feature_config[dataset_name],\n",
    "    interaction_features=[('age', 'sex')],\n",
    "    time_col=time_col,\n",
    "    event_col=event_col\n",
    ")\n",
    "\n",
    "# get log dir\n",
    "model_name = 'cox_age_sex'\n",
    "log_dir_path = get_log_dir_path(model_name)\n",
    "\n",
    "# get checkpoint callback\n",
    "checkpoint_callback = get_checkpoint_callback(model_name, log_dir_path)\n",
    "\n",
    "# get trainer\n",
    "trainer = get_trainer(model_name, checkpoint_callback)\n",
    "\n",
    "print(\"Training model\")\n",
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266ed6b2cc93bcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:52:27.519003Z",
     "start_time": "2025-01-17T23:52:27.212391Z"
    }
   },
   "outputs": [],
   "source": [
    "X = merge_batches(datamodule.train_dataloader())\n",
    "X, _, _ = model.get_xtc(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a85b3ecaa3cac6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:53:33.332990Z",
     "start_time": "2025-01-17T23:52:32.543019Z"
    }
   },
   "outputs": [],
   "source": [
    "# get model coefficient pvalues\n",
    "cox_pvals = model.get_coefficient_pvals(X)\n",
    "pvals_df = pd.DataFrame.from_dict(cox_pvals, columns=['Coefficient p-values'], orient='index')\n",
    "\n",
    "latex_tab = pvals_df.to_latex(index=True, \n",
    "                            float_format=\"%.3f\",\n",
    "                            label=f'tab:cox_pvals',\n",
    "                            caption=f'Cox model coefficient p-values',\n",
    "                            sparsify=True)\n",
    "latex_tab = latex_tab.replace('pval_', '').replace('_', ' ')\n",
    "print(latex_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc70b2d-cc66-42d0-8b37-8251f9e66636",
   "metadata": {
    "id": "0cc70b2d-cc66-42d0-8b37-8251f9e66636"
   },
   "source": [
    "## Task 1.3: Deep Survival Prediction for Heart Transplantation [8 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d97445-e2aa-4429-9655-5c25041b2c67",
   "metadata": {
    "id": "36d97445-e2aa-4429-9655-5c25041b2c67"
   },
   "source": [
    "####  Setup and Dataset\n",
    "\n",
    "For this task, we will use data collected by the United Network for Organ Sharing (UNOS) [2], a non-profit organization that administers the only Organ Procurement and Transplantation Network (OPTN) in the US. UNOS is involved in many aspects of the organ transplant and donation process in the US, including data collection and maintenance, providing assitance to patients and care takers, and informing policy makers on the best use of the limited supply of organs and give all patients a fair chance at receiving the organ they need. UNOS manages the heart transplant waiting list, i.e., the list of terminally-ill patients waiting for donor heart. In order to determine the order of priority for receipt of a donor heart, individuals are classified by degrees of severity for a donor heart, blood type, body weight, and geographic location.\n",
    "\n",
    "This Task will focus on the cohort of terminally-ill patients who are enrolled in the wait-list for heart transplantation. In this setup, our goal is to predict the patients who are less likely to survive in order to prioritize them for receiving donated organs. The UNOS data covers 30 years of heart transplantation data in the US, spanning the years from 1985 to 2015. We will use data for patients who were on the wait-list for heart transplantation in the US from 1985 to 2010 (27,926 patients) to train an ML-based model for predicting individual-level survival. A held-out test set of 8,403 patients enrolled in the wait-list between 2010 and 2015 will be used by the instructor to evaluate your model. You can load the UNOS data in pandas as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba14399b5fda90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.directory import csv_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e147b2a3-26d5-4bbc-8266-61f71ca8be9d",
   "metadata": {
    "id": "e147b2a3-26d5-4bbc-8266-61f71ca8be9d"
   },
   "outputs": [],
   "source": [
    "UNOS_data = pd.read_csv(csv_paths['unos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3188984f40bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNOS_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f65a78610cfb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNOS_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52750ffcdc41b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'NA Count by Variable : {UNOS_data.isna().sum(axis=0)[UNOS_data.isna().sum(axis=0) > 0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c649f9-08b6-4496-8bf3-31ae2106c0fd",
   "metadata": {
    "id": "a2c649f9-08b6-4496-8bf3-31ae2106c0fd"
   },
   "source": [
    "#### Feature Dictionary\n",
    "\n",
    "Each patient's record in the UNOS database is associated with the following variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21caaba9-5f43-4c70-8265-afce7e77782d",
   "metadata": {
    "id": "21caaba9-5f43-4c70-8265-afce7e77782d"
   },
   "outputs": [],
   "source": [
    "patient_variables   = [\"init_age\", \"gender\", \"hgt_cm_tcr\", \"wgt_kg_tcr\", \"diab\", \"ventilator_tcr\",\n",
    "                       \"ecmo_tcr\", \"most_rcnt_creat\", \"abo_A\", \"abo_B\", \"abo_O\", \"vad_while_listed\",\n",
    "                       \"days_stat1\", \"days_stat1a\", \"days_stat2\", \"days_stat1b\", \"iabp_tcr\",\n",
    "                       \"init_bmi_calc\", \"tah\", \"inotropic\", \"Censor (Censor = 1)\", \"Survival Time\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224d7db7-36fa-4285-8dc1-fb202b608f7a",
   "metadata": {
    "id": "224d7db7-36fa-4285-8dc1-fb202b608f7a"
   },
   "source": [
    "The interpretation of each variable is provided below:\n",
    "\n",
    "- \"init_age\": Patient's age at time of enrolling in the wait-list\n",
    "- \"gender\": Patient's biological sex\n",
    "- \"hgt_cm_tcr\": Patient's height in cm\n",
    "- \"wgt_kg_tcr\": Patient's weight in kgs\n",
    "- \"diab\": Indication on whether or not the patient is diabetic\n",
    "- \"abo_A\": Indication on whether patient's blood type is A\n",
    "- \"abo_B\": Indication on whether patient's blood type is B\n",
    "- \"abo_O\": Indication on whether patient's blood type is O\n",
    "- \"ventilator_tcr\": Indication on whether the patient was dependent on a ventilator at time of enrollment in the wait-list\n",
    "- \"ecmo_tcr\": Indication on whether the patient was treated with ECMO (extracorporeal membrane oxygenation) by the time they where enrolled in the wait-list. ECMO is an artificial life support that continuously pumps blood out of the patient's body and sends it through a series of devices that add oxygen and remove carbon dioxide, pumping the blood back to the patient. It is used for a patient whose heart and lungs are not functioning properly.  \n",
    "- \"most_rcnt_creat\": Creatinine level in the patient's most recent blood test before enrolling in wait-list.\n",
    "- \"vad_while_listed\": Whether the patient was on ventricular assist device (VAD) support when listed for a heart transplant. VAD is a mechanical pump used to restore cardiac function by pumping blood from the lower chambers of the heart to the rest of the body.\n",
    "- \"iabp_tcr\": Whether the patient was on Intra-Aortic Balloon Pump (IABP) Therapy. This is a therapeutic device used to improve blood flow when the heart is unable to pump enough blood for your body.\n",
    "- \"init_bmi_calc\": Patient's Body Mass Index at time of enrollment in the wait-list.\n",
    "- \"tah\": Whether the patient underwent a total artificial heart (TAH) surgery. This is a mechanical pump that replaces the heart when it is not working as it should.\n",
    "- \"inotropic\": Whether the patient was on an Inotropic drug at time of enrollment in wait-list. These are medicines that change the force of the heart's contractions.\n",
    "- \"days_stat1\", \"days_stat1a\", \"days_stat1b\", \"days_stat2\": UNOS has an internal system for classifying the priority of patients for receiving a heart transplant. Individuals classified as Status 1A have the highest priority on the heart transplant waiting list. Status 1A are individuals who must stay in the hospital as in-patients and require high doses of intravenous drugs, require a VAD for survival, are dependent on a ventilator or have a life expectancy of a week or less without a transplant. Individuals classified as Status 1B are generally not required to stay in the hospital as in-patients. All other candidates for the transplant are listed under Status 2. These variables indicate the number of days a patient spends in each status during the time between their enrollment in the wait-list and death or reception of a transplant.\n",
    "- \"Censor (Censor = 1)\": Indication of censoring\n",
    "- \"Survival Time\": Time between enrollment in wait-list and death"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481eae55-45ef-46b9-9d45-a0a63f1da3d8",
   "metadata": {
    "id": "481eae55-45ef-46b9-9d45-a0a63f1da3d8"
   },
   "source": [
    "### Task 1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392a9b1f33fdadc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:44:27.850737Z",
     "start_time": "2025-01-17T23:44:26.592201Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.data_dict import feature_config\n",
    "from src.directory import csv_paths, deep_survival_model_path\n",
    "from src._torch import DeepSurvival\n",
    "from lifelines import KaplanMeierFitter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b0a28238dbcecf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:50:23.746826Z",
     "start_time": "2025-01-17T23:50:23.691724Z"
    }
   },
   "outputs": [],
   "source": [
    "event_col = \"Censor (Censor = 1)\"\n",
    "time_col = \"Survival Time\"\n",
    "\n",
    "UNOS_data = pd.read_csv(csv_paths['unos'])\n",
    "X = UNOS_data[feature_config['unos']].to_numpy()\n",
    "T = UNOS_data[time_col].to_numpy()\n",
    "C = UNOS_data[event_col].to_numpy()\n",
    "n_features = X.shape[1]\n",
    "\n",
    "X_train, X_test, T_train, T_test, C_train, C_test = train_test_split(X, T, C, test_size=.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa53cdd-d1af-4c4e-99ad-cea20184c547",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:50:36.915697Z",
     "start_time": "2025-01-17T23:50:24.232193Z"
    },
    "id": "afa53cdd-d1af-4c4e-99ad-cea20184c547"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(40)\n",
    "model = DeepSurvival(save_path=deep_survival_model_path)\n",
    "model.fit(X_train, T_train, C_train, lr=3e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef333a0a87585be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:50:40.688244Z",
     "start_time": "2025-01-17T23:50:40.102916Z"
    }
   },
   "outputs": [],
   "source": [
    "# check test c_index\n",
    "cindex = model.get_cindex(X_test, T_test, C_test)\n",
    "print('C-index on test set:', cindex.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2bc4a61ed30ce3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:50:41.841257Z",
     "start_time": "2025-01-17T23:50:41.820567Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X, max_years=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270bab68b937ea8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T23:50:49.372050Z",
     "start_time": "2025-01-17T23:50:49.285784Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot mean survival curve\n",
    "plt.plot(predictions.mean(axis=0), label='DeepSurvival')\n",
    "\n",
    "# plot KM survival curve\n",
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit(UNOS_data[time_col]/365, event_observed=UNOS_data[event_col])\n",
    "kmf.plot_survival_function(label='Lifelines KM')\n",
    "\n",
    "# adjust plot\n",
    "plt.xlim((-0.5, 10))\n",
    "plt.ylim((0,1.05))\n",
    "plt.xlabel(\"Years\")\n",
    "plt.ylabel(\"Survival Probability\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34zzM6FhbUud",
   "metadata": {
    "id": "34zzM6FhbUud"
   },
   "source": [
    "## Task 1.4: Handling Informative Censoring via Domain Adaptation [8 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e80edc3",
   "metadata": {},
   "source": [
    "### Task 1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XuwUXwAEbPSN",
   "metadata": {
    "id": "XuwUXwAEbPSN"
   },
   "outputs": [],
   "source": [
    "from pycox import datasets\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from src.informative_censoring import check_informative_censoring, generate_semi_synthetic_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3899f108-00e5-467e-b49d-56919be68144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note: \"['Unnamed: 0'] not found in axis\" error received reading in flchain & nwtco:\n",
    "# To fix error: replace the following lines pycox/datasets/from_rdatasets.py:\n",
    "# line 78: .drop(['chapter', 'Unnamed: 0', 'rownames'], axis=1, errors='ignore')\n",
    "# line 146: .drop(['Unnamed: 0', 'seqno', 'instit', 'histol', 'study', 'rownames'], axis=1, errors='ignore'))\n",
    "\n",
    "dataset_dict = dict(zip(['flchain', 'gbsg', 'metabric', 'nwtco'], \n",
    "                         [datasets.flchain.read_df(), \n",
    "                          datasets.gbsg.read_df(), \n",
    "                          datasets.metabric.read_df(), \n",
    "                          datasets.nwtco.read_df()]))\n",
    "\n",
    "for name, dataset in dataset_dict.items():\n",
    "    dataset.name = name\n",
    "    \n",
    "\n",
    "time_col_dict = dict(zip(dataset_dict.keys(),\n",
    "                         ['futime',\n",
    "                          'duration',\n",
    "                          'duration',\n",
    "                          'edrel']))\n",
    "\n",
    "event_col_dict = dict(zip(dataset_dict.keys(),\n",
    "                         ['death',\n",
    "                          'event',\n",
    "                          'event',\n",
    "                          'rel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cecef8a-6275-4256-b6cc-6405951d2443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for informative censoring\n",
    "results = {}\n",
    "for name, dataset in dataset_dict.items():\n",
    "    time_col, event_col = time_col_dict[name], event_col_dict[name]\n",
    "    results[name] = check_informative_censoring(dataset, time_col, event_col)\n",
    "\n",
    "# print results\n",
    "for name, r in results.items():\n",
    "    print(name, '\\n', r.loc[['informative_censoring']].T, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2136a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format df of p-values\n",
    "informative_censoring_df = []\n",
    "for name, r in results.items():\n",
    "    temp_df = pd.DataFrame.from_dict(r).loc[['p_value']]\n",
    "    temp_df = temp_df.reset_index().drop(columns=['spearmanr_results', 'feature']).T\n",
    "    temp_df['dataset'] = name\n",
    "    # temp_df = temp_df.rename\n",
    "    temp_df = temp_df.reset_index().set_index(['dataset', 'index'])\n",
    "    informative_censoring_df.append(temp_df)\n",
    "informative_censoring_df = pd.concat(informative_censoring_df)\n",
    "informative_censoring_df.index = informative_censoring_df.index.rename({'index': 'feature'})\n",
    "informative_censoring_df.columns = ['p-value']\n",
    "\n",
    "# get latex table\n",
    "latex_tab = informative_censoring_df.to_latex(index=True, \n",
    "                                            float_format=\"%.3f\",\n",
    "                                            label=f'tab:spearman_pvals',\n",
    "                                            caption=f'Informative censoring p-values',\n",
    "                                            sparsify=True)\n",
    "latex_tab = latex_tab.replace('_', ' ')\n",
    "print(latex_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f937a485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visually inspect time-dependent censoring\n",
    "fig, axs = plt.subplots(2,2)\n",
    "axs = axs.ravel()\n",
    "for i, (name, dataset) in enumerate(dataset_dict.items()):\n",
    "    time_col, event_col = time_col_dict[name], event_col_dict[name]\n",
    "    sns.violinplot(dataset, x=time_col, hue=event_col, ax=axs[i], split=True, cut=0)\n",
    "    axs[i].set_title(name)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33c4c39-ab1a-4769-b0df-e0b58d1b25f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate semi synthetic data\n",
    "synthetic_data = {}\n",
    "for name, dataset in dataset_dict.items():\n",
    "    time_col, event_col = time_col_dict[name], event_col_dict[name]\n",
    "    synthetic_data[name] = generate_semi_synthetic_dataset(dataset, time_col, event_col, max_loops=10)\n",
    "    synthetic_data[name].name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1888dc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visually inspect time-dependent censoring\n",
    "fig, axs = plt.subplots(2,2)\n",
    "axs = axs.ravel()\n",
    "for i, (name, dataset) in enumerate(synthetic_data.items()):\n",
    "    time_col, event_col = time_col_dict[name], event_col_dict[name]\n",
    "    sns.violinplot(dataset, x=time_col, hue=event_col, ax=axs[i], split=True, cut=0)\n",
    "    axs[i].set_title(f'{name}_synth')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee05b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for informative censoring\n",
    "results = {}\n",
    "for name, dataset in synthetic_data.items():\n",
    "    time_col, event_col = time_col_dict[name], event_col_dict[name]\n",
    "    results[name] = check_informative_censoring(dataset, time_col, event_col)\n",
    "\n",
    "# print results\n",
    "for name, r in results.items():\n",
    "    time_col = time_col_dict[name]\n",
    "    print(f'{name}_synth', '\\n', r.loc[['informative_censoring']].T, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0984f2",
   "metadata": {},
   "source": [
    "### Task 1.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eae22aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src._torch import DeepSurvival\n",
    "from src.directory import deep_survival_model_path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fa7834",
   "metadata": {},
   "outputs": [],
   "source": [
    "multindex = pd.MultiIndex.from_product(iterables=[synthetic_data.keys(), ['vanilla', 'importance sampling']], names=['dataset', 'method'])\n",
    "c_index_df = pd.DataFrame(index=multindex, columns=['c-index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd55574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified modal with importance weighting ERM\n",
    "for name, dataset in synthetic_data.items():\n",
    "\n",
    "    # set up data\n",
    "    time_col, event_col = time_col_dict[name], event_col_dict[name]\n",
    "    feature_cols = list(set(dataset.columns) - set([time_col, event_col]))\n",
    "\n",
    "    X = dataset[feature_cols].to_numpy()\n",
    "    T = dataset[time_col].to_numpy()\n",
    "    C = dataset[event_col].to_numpy()\n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, T_train, T_test, C_train, C_test = train_test_split(X, T, C, test_size=.2, random_state=40)\n",
    "\n",
    "    # get save path\n",
    "    save_path = os.path.join(os.path.dirname(deep_survival_model_path), f'best_model_DA_{name}.pth')\n",
    "\n",
    "    # init and train model\n",
    "    torch.manual_seed(40)\n",
    "    model = DeepSurvival(dataset_name=name,\n",
    "                         save_path=save_path,\n",
    "                         clinical_features=feature_cols,\n",
    "                         importance_weighting=True)\n",
    "    model.fit(X_train, T_train, C_train)\n",
    "\n",
    "    # check test c_index\n",
    "    cindex = model.get_cindex(X_test, T_test, C_test).item()\n",
    "    c_index_df.loc[(name, 'importance sampling')] = cindex\n",
    "    print(f'C-index on {name}_synth test set:', cindex, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a4cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original model\n",
    "for name, dataset in synthetic_data.items():\n",
    "\n",
    "    # set up data\n",
    "    time_col, event_col = time_col_dict[name], event_col_dict[name]\n",
    "    feature_cols = list(set(dataset.columns) - set([time_col, event_col]))\n",
    "\n",
    "    X = dataset[feature_cols].to_numpy()\n",
    "    T = dataset[time_col].to_numpy()\n",
    "    C = dataset[event_col].to_numpy()\n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, T_train, T_test, C_train, C_test = train_test_split(X, T, C, test_size=.2, random_state=40)\n",
    "\n",
    "    # get save path\n",
    "    save_path = os.path.join(os.path.dirname(deep_survival_model_path), f'best_model_{name}.pth')\n",
    "\n",
    "    # init and train model\n",
    "    torch.manual_seed(40)\n",
    "    model = DeepSurvival(dataset_name=name,\n",
    "                         save_path=save_path,\n",
    "                         clinical_features=feature_cols,\n",
    "                         importance_weighting=False)\n",
    "    model.fit(X_train, T_train, C_train)\n",
    "\n",
    "    # check test c_index\n",
    "    cindex = model.get_cindex(X_test, T_test, C_test).item()\n",
    "    c_index_df.loc[(name, 'vanilla')] = cindex\n",
    "    print(f'C-index on {name}_synth test set:', cindex, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get latex table\n",
    "latex_tab = c_index_df.to_latex(index=True, \n",
    "                            float_format=\"%.3f\",\n",
    "                            label=f'tab:informative censoring c-index',\n",
    "                            caption=f'C-index on benchmark dataset test sets',\n",
    "                            sparsify=True)\n",
    "print(latex_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdafc12b-0755-4289-aa17-6fe5e254df45",
   "metadata": {
    "id": "cdafc12b-0755-4289-aa17-6fe5e254df45",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## References\n",
    "\n",
    "[1] Chicco, Davide, and Giuseppe Jurman. “Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone.” BMC Medical Informatics and Decision Making, vol.\n",
    "20, no. 1 (2020): 1-16.\n",
    "\n",
    "[2] Weiss, Eric S., Lois U. Nwakanma, Stuart B. Russell, John V. Conte, and Ashish S. Shah. “Outcomes in\n",
    "bicaval versus biatrial techniques in heart transplantation: an analysis of the UNOS database.” The Journal\n",
    "of heart and lung transplantation, vol. 27, no. 2 (2008): 178-183."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cph-200b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
